\hypertarget{verification-results}{%
\chapter{Verification Results}\label{verification-results}}


\hypertarget{compilation-directives}{%
\section{Compilation Directives}\label{compilation-directives}}

Spin supports many compile-time directives which allows for specifying the possible time-memory trade-off strategies which are desirable when verifying the specific model.
Not all compile time directives are compatible with all models.
Some directives require a proof by the user that certain conditions hold within the model for the directive's usage to be sound.
Furthermore, many directives' usage are are mutually exclusive with one or more other directives.
Still, with these restrictions in mind, the careful selection of compile-time directives is vital to successfully grappling with the enormity of memory usage resulting from the potentially exponential state-space explosion.


\hypertarget{partial-order-reduction}{%
\subsection{Partial Order Reduction}\label{partial-order-reduction}}

Partial-order reduction methods represent a well understood collection of state exploration techniques \autocite{godefroid1990using}, \autocite{godefroid1991using}, \autocite{godefroid1994partial}, \autocite{holzmann1995improvement}, \autocite{katz1992verification}, \autocite{peled1993all}, \autocite{valmari1989stubborn}, \autocite{valmari1992stubborn} whose combined usage can greatly reduce the model checking search-space.
Such techniques are applicable for verifying local and termination of concurrent models.
Furthermore, these techniques are equally applicable for verifying LTL properties, even reducing the state-space when verifying liveness and safety properties within concurrent models \autocite{wolper1983reasoning}.
The specific partial order reduction technique of ``simultaneous reachability'' analysis \autocite{van1997partial} enables the verification of non-executable transitions, absence of deadlock, and buffer overflows.
The extensive research and engineering effort put into the myriad of partial order reduction techniques have all been incorporated into verification strategies of SPIN, and are enabled by default,requiring manual ``opt-out'' compilation directives in order to disable them.
SPIN intelligently selects applicable partial order reduction techniques for the concurrency of the model, the LTL properties to be verified, and the topology of the state-space.
The verification work presented permitted the usage all the partial order reduction technique made available by SPIN.
No comparative verification(s) were made to observe the run-time difference between explicitly forbidding partial order reduction and permitting the ``enabled by default'' techniques available to SPIN.

The verification work refrained from from both disabling partial order reduction via the \texttt{NOREDUCE} directive as well as experiment with potential performance gains or regressions introduced by the \texttt{NIBIS} directive.
Instead this work made use of a single partial order reduction directive:

\begin{itemize}
\item
  \texttt{XUSAFE}
\end{itemize}

The \texttt{XUSAFE} directive disables validity checks of the strictly synchronizing message passing queues.
The encoded model of TreeKEM does not utilize these queues, hence any check related to them would be superfluous.
No noticeable performance gains were observed by utilizing the \texttt{XUSAFE}, but it's usage was retained regardless.


\hypertarget{state-vector-encoding}{%
\subsection{State Vector Encoding}\label{state-vector-encoding}}

Each state within the model's state-space is encoded as a ``state-vector.''
The state vectors uniquely map to each state within the model.
Given that the main memory requirements of model checking lies in exhaustive state-space search, it is unsurprising that specifying the encoding of the state-vectors has a pronounced impact on memory usage.
There are to relevant directives used to influence the model checker's representation of state-vectors.
Note that all four directives can be used in conjunction for compounding effects.

\begin{itemize}
\item
  \texttt{COLLAPSE}
\item
  \texttt{VECTORSZ=}\(X\)
\item
  \texttt{MA=}\(X\)
\item
  \texttt{SPACE}
\end{itemize}

The \texttt{VECTORSZ} directive is used to specify the number of byte \(X\) to allocate for each state-vector.
Specifying a number of bytes which is insufficient to represent the state vector will cause the compilation of the model to fail with an approximate suggestion of the correct number of bytes to specify.
The \texttt{VECTORSZ} directive is required when the state-vector length exceeds the SPIN default of \(1024\) bytes.
Likewise, the \texttt{COLLAPSE} directive applies compression the the state-vector representation.

A final two memory related directives are utilized conditionally during the verification of TreeKEM.
For large values of \(T\) and \(N\), the \texttt{MA} and \texttt{SPACE} directives are utilized in conjunction to increase the tractable values of \(T_{max}\) and \(N_{max}\).
The conjunction of these two directives produces a very significant memory reduction, however the usage of \texttt{MA} causes an appreciable increase in verification run-time.
This time-memory trade-off is necessary to make verification of higher \(T_{max}\) and \(N_{max}\) values tractable, even on modern computing cluster hardware.

The \texttt{MA} directive is used to specify the maximum number of bytes \(X\) that a state vector can require.
Spin internally stores several sets of model states.
Using the information regarding the upper bound \(X\) for state-vector bytes, the \texttt{MA} directive enables a method of storing a set of states is a binary decision tree (BDD) \autocite{holzmann1999minimized}.
To determine if the state is in the set, Spin treated the state vector as a bit-sting and feeds it to the BDD, with BDD accepting the string treating the state is in the set, the BDD rejecting the string representing state is not being in the set.
Further steps are taken to reduce the BDD into a minimal DFA representation of a 256-ary decision tree.
Insertion, deletion, and membership queries take linear time in the length of the state-vector.
The translation alone between DFA representation represents a stark time/memory trade-off, as linear time set membership is a stark difference between Spin's default hash-set storage method, resulting in reducing memory requirements while increasing verification run-time.

The \texttt{SPACE} directive instructs the compiler to encode the state transition graph as well as select search algorithms with the goal of reducing memory usage at the expense of verification time.
During verification of TreeKEM, it is always the case that the \texttt{SPACE} directive is utilized if and only if the \texttt{MA} is also utilized.
This conditional directive usage creates an ``optimization partition'' bifurcating verification runs into two sets of utilized directives.
An important consequence of this partitioning relates to comparative analysis of the verification run-time characteristics.
Such comparisons can only soundly be with other verification runs within the same set, utilizing the same directives.
In the tables presented below, the presence of a checkmark (\cmark) in the column labeled $\MinimizedDFA$ indicates that the associated parameterized model and results were run with this time/memory trade-off strategy enabled.


\hypertarget{multi-core-tuning}{%
\subsection{Multi-core Tuning}\label{multi-core-tuning}}

Since version 5.0, SPIN has supported performing model checking on multi-core machines \autocite{holzmann2007design}.
This support brings with it non-trivial engineering considerations, such as how to ensure partial order reduction remains sound across multiple independent processors, how to exchange search state results between processors, how to share or segregate memory, and how to minimize parallelism overhead.
There are two primary directives used my SPIN for approximating the optimal multi-core verification strategy at compile-time.
Both of these are used by this work while verifying TreeKEM.

\begin{itemize}
\item
  \texttt{MEMLIM=}\(X\)
\item
  \texttt{NCORE=}\(Y\)
\end{itemize}

The \texttt{MEMLIM} directive specifies the upper limit of memory usable by the model checker to be \(X\) mebibytes for the duration it's verification.
Specifying this has the important effect of preventing the verification process from thrashing by utilizing more virtual memory than real memory exists on the verification machine(s).
Moreover, the \texttt{NCORE} directive informs the model checker at compile-time the maximum number of usable processors is \(Y\), permitting the compiler to make informed approximations to minimize parallelism overhead and maximize multi-core throughput.
The verification work's utilization of both \texttt{MEMLIM} and \texttt{NCORE} directives when utilizing a multi-core computing cluster had notable impact on the overall ``states per second'' processing performance.


\hypertarget{run-time-improvement}{%
\subsection{Run-time Improvement}\label{run-time-improvement}}

Without any special direction SPIN includes a number of run-time checks and overhead structures to support functionality which may or may not actually be required for verification.
For each of these ``safety rails'' added to the verification by default, there exists a directive to remove the run-time feature.
The verification of TreeKEM does not require all run-time features and the following directives are used to remove the associated run-time increases.

\begin{itemize}
\item
  \texttt{NOBOUNDCHECK}
\item
  \texttt{NOFAIR}
\end{itemize}

The \texttt{NOBOUNDCHECK} directive removes run-time bounds checking when indexing arrays.
While enabled, the bound checking provides extremely useful debugging information.
Enabling bounds checking is useful while developing the model, but once confidence has been established that indexing errors do not exist in the model, such bounds checks are superfluous.
Additionally, the \texttt{NOBOUNDCHECK} performs run-time checks when synchronously accessing message queues.
The TreeKEM model does not use such message channels.
Consequently, the finalized model does not require bounds checking and the disabling directive is used during verification.

Similarly the \texttt{NOFAIR} removes the data structures and tracking subroutines required to reason about and verify fairness properties.
The verification of TreeKEM does not include any fairness properties.
Hence the \texttt{NOFAIR} directive is always enabled.


\hypertarget{reproducible-randomness}{%
\subsection{Reproducible Randomness}\label{reproducible-randomness}}

Like many problems with arbitrary alternation or stochastic search strategies, SPIN provides the opportunity for specifying seeds to exactly reproduce the results of random selection.
The benefits of reproducibility are difficult to understate.
Before the model is finalized, reproducibility is essential during the debugging process.
On the other hand, once the model is finalized, reproducibility is required for certainty during peer review.
Hence, directives for specify seed values are utilized throughout the verification work.

\begin{itemize}
\item
  \texttt{P\_RAND=}\(X\)
\item
  \texttt{T\_RAND=}\(Y\)
\end{itemize}

The first randomness directive, \texttt{P\_RAND}, is utilized to specify the random seed which determines process scheduling order for multi-process models.
The second, \texttt{T\_RAND} is also utilized, and corresponding the seed value dictates the transition exploration order when traversing the state-space.
Random seed values for \texttt{P\_RAND} and \texttt{T\_RAND} were set by manipulating the known numerical constants as defined below.
The transparency of the random seed value selection exists as a ``no tricks up my sleeve'' technique for specifying arbitrary seed values.

\begin{equation}
\begin{aligned}[t]
X = \texttt{1618033988} = & \bigg | \, \phi          \!\!\!\! & * \, 10^9 \, \bigg |\\
Y = \texttt{1155727349} = & \bigg | \, \frac{\pi}{e} \!\!\!\! & * \, 10^9 \, \bigg |\\
\end{aligned}
\end{equation}


\subimport{../tables/}{results-V1-HLT-PRELIM}


\hypertarget{post-compromise-security}{%
\section{Post Compromise Security}\label{post-compromise-security}}

\subimport{../tables/}{results-V1-PCS-PRELIM}


\hypertarget{future-secrecy}{%
\section{Future Secrecy}\label{future-secrecy}}

\subimport{../tables/}{results-V1-FSU-PRELIM}


\hypertarget{scalability-limits}{%
\section*{Scalability Limits}\label{scalability-limits}}
\addcontentsline{toc}{subsection}{Scalability Limits}
